{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Use GPU for faster computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "print(\"GPU available:\", torch.cuda.is_available())\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Run on CLASSIC DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Import CLASSIC DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR CLASSIC DATA ORDERING\n",
    "\n",
    "import numpy as np\n",
    "import pooch\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "rnd_seed = 42\n",
    "rnd_gen = np.random.default_rng(rnd_seed)\n",
    "\n",
    "# Define paths\n",
    "base_dir = Path(r'C:\\Users\\bapti\\Downloads\\ML_Project\\Copy_full_fish_dataset')\n",
    "#base_dir = Path(r'C:\\Users\\bapti\\Downloads\\Mask_creation')\n",
    "output_dir = Path(r'C:\\Users\\bapti\\Downloads\\ML_Project\\Data_ready')\n",
    "#output_dir = Path(r'C:\\Users\\bapti\\Downloads\\Mask_data_ready')\n",
    "train_dir = output_dir / 'Train'\n",
    "valid_dir = output_dir / 'Valid'\n",
    "test_dir = output_dir / 'Test'\n",
    "\n",
    "# Ensure output directories exist\n",
    "for path in [train_dir, valid_dir, test_dir]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Collect all images with metadata\n",
    "data = []\n",
    "test_data = []\n",
    "\n",
    "for class_name in [\"LEFT\", \"RIGHT\"]:\n",
    "    class_dir = base_dir / class_name\n",
    "    for species_name in [\"Grayling\", \"Trout\"]:\n",
    "        species_dir = class_dir / species_name\n",
    "        for date_folder in species_dir.iterdir():\n",
    "            if date_folder.is_dir():\n",
    "                date = date_folder.name\n",
    "                for image_file in date_folder.glob('*.*'):\n",
    "                    # Store metadata with each image path\n",
    "                    item = {\n",
    "                        \"path\": image_file,\n",
    "                        \"class\": class_name,\n",
    "                        \"species\": species_name,\n",
    "                        \"date\": date\n",
    "                    }\n",
    "                    # Assign test data based on specified conditions\n",
    "                    if (species_name == \"Grayling\" and date == \"Day_35\") or \\\n",
    "                       (species_name == \"Trout\" and date == \"Day_146\"):\n",
    "                        test_data.append(item)\n",
    "                    else:\n",
    "                        data.append(item)\n",
    "\n",
    "# Shuffle data for random splitting\n",
    "random.seed(123)  # For reproducibility\n",
    "random.shuffle(data)\n",
    "\n",
    "# Split remaining data into train (85%) and validation (15%)\n",
    "total_count = len(data)\n",
    "train_count = int(0.85 * total_count)\n",
    "\n",
    "train_data = data[:train_count]\n",
    "valid_data = data[train_count:]\n",
    "\n",
    "# Convert lists of metadata to DataFrames for easier access\n",
    "train_df = pd.DataFrame(train_data)\n",
    "valid_df = pd.DataFrame(valid_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# Save metadata DataFrames to CSV files for future use\n",
    "train_df.to_csv(output_dir / 'train_metadata.csv', index=False)\n",
    "valid_df.to_csv(output_dir / 'valid_metadata.csv', index=False)\n",
    "test_df.to_csv(output_dir / 'test_metadata.csv', index=False)\n",
    "\n",
    "# Function to copy images to output directory with new structure\n",
    "def copy_images(data_split, target_dir):\n",
    "    for item in data_split:\n",
    "        target_class_dir = target_dir / item[\"class\"]\n",
    "        target_species_dir = target_class_dir / item[\"species\"]\n",
    "        target_species_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Copy image to the new directory, preserving original filename\n",
    "        shutil.copy(item[\"path\"], target_species_dir / item[\"path\"].name)\n",
    "\n",
    "# Copy images to respective folders\n",
    "copy_images(train_data, train_dir)\n",
    "copy_images(valid_data, valid_dir)\n",
    "copy_images(test_data, test_dir)\n",
    "\n",
    "# Load the datasets from the new directories\n",
    "train_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(256, 256),  # Specify your desired image size\n",
    "    batch_size=32,          # Specify your desired batch size\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "valid_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    valid_dir,\n",
    "    image_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "test_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "train_set.name = 'Training'\n",
    "valid_set.name = 'Validation'\n",
    "test_set.name = 'Test'\n",
    "\n",
    "# Print class names and dataset sizes\n",
    "class_names = train_set.class_names\n",
    "print(\"Class names:\", class_names)\n",
    "print(\"Training dataset size:\", len(train_set))\n",
    "print(\"Validation dataset size:\", len(valid_set))\n",
    "print(\"Test dataset size:\", len(test_set))\n",
    "\n",
    "# Print number of test images\n",
    "print(\"\\n\",\"Total number of images in the input dataset:\", \"\\n\",\"train + valid:\",len(data), \"\\n\",\"test:\",len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #FOLLOWING CODE FOR CLASSIC DATA WITHOUT ORDERING (IF THE ORDERING HAS ALREADY BEEN DONE WITH THE ABOVE CELL)\n",
    "\n",
    "# from PIL import Image\n",
    "# import tensorflow as tf\n",
    "# import os\n",
    "# import random\n",
    "# import shutil\n",
    "# from pathlib import Path\n",
    "# import pandas as pd\n",
    "\n",
    "# # Define paths\n",
    "# base_dir = Path(r'C:\\Users\\bapti\\Downloads\\ML_Project\\Copy_full_fish_dataset')\n",
    "# #base_dir = Path(r'C:\\Users\\bapti\\Downloads\\Mask_creation')\n",
    "# output_dir = Path(r'C:\\Users\\bapti\\Downloads\\ML_Project\\Data_ready')\n",
    "# #output_dir = Path(r'C:\\Users\\bapti\\Downloads\\Mask_data_ready')\n",
    "\n",
    "# #For Ubuntu: \n",
    "# base_dir = Path('/mnt/c/Users/bapti/Downloads/ML_Project/Copy_full_fish_dataset')\n",
    "# output_dir = Path('/mnt/c/Users/bapti/Downloads/ML_Project/Data_ready')\n",
    "\n",
    "# train_dir = output_dir / 'Train'\n",
    "# valid_dir = output_dir / 'Valid'\n",
    "# test_dir = output_dir / 'Test'\n",
    "\n",
    "# # Ensure output directories exist\n",
    "# for path in [train_dir, valid_dir, test_dir]:\n",
    "#     path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Collect all images with metadata\n",
    "# data = []\n",
    "# test_data = []\n",
    "\n",
    "# for class_name in [\"LEFT\", \"RIGHT\"]:\n",
    "#     class_dir = base_dir / class_name\n",
    "#     for species_name in [\"Grayling\", \"Trout\"]:\n",
    "#         species_dir = class_dir / species_name\n",
    "#         for date_folder in species_dir.iterdir():\n",
    "#             if date_folder.is_dir():\n",
    "#                 date = date_folder.name\n",
    "#                 for image_file in date_folder.glob('*.*'):\n",
    "#                     # Store metadata with each image path\n",
    "#                     item = {\n",
    "#                         \"path\": image_file,\n",
    "#                         \"class\": class_name,\n",
    "#                         \"species\": species_name,\n",
    "#                         \"date\": date\n",
    "#                     }\n",
    "#                     # Assign test data based on specified conditions\n",
    "#                     if (species_name == \"Grayling\" and date == \"Day_35\") or \\\n",
    "#                        (species_name == \"Trout\" and date == \"Day_146\"):\n",
    "#                         test_data.append(item)\n",
    "#                     else:\n",
    "#                         data.append(item)\n",
    "\n",
    "# #FOR CLASSIC DATA ORDERING\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import os\n",
    "# import random\n",
    "# import shutil\n",
    "# from pathlib import Path\n",
    "# import pandas as pd\n",
    "\n",
    "# # Define paths\n",
    "# #base_dir = Path(r'C:\\Users\\bapti\\Downloads\\ML_Project\\Copy_full_fish_dataset')\n",
    "# base_dir = Path(r'C:\\Users\\bapti\\Downloads\\Mask_creation')\n",
    "# #output_dir = Path(r'C:\\Users\\bapti\\Downloads\\ML_Project\\Data_ready')\n",
    "# output_dir = Path(r'C:\\Users\\bapti\\Downloads\\Mask_data_ready')\n",
    "# train_dir = output_dir / 'Train'\n",
    "# valid_dir = output_dir / 'Valid'\n",
    "# test_dir = output_dir / 'Test'\n",
    "\n",
    "# # Ensure output directories exist\n",
    "# for path in [train_dir, valid_dir, test_dir]:\n",
    "#     path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Collect all images with metadata\n",
    "# data = []\n",
    "# test_data = []\n",
    "\n",
    "# for class_name in [\"LEFT\", \"RIGHT\"]:\n",
    "#     class_dir = base_dir / class_name\n",
    "#     for species_name in [\"Grayling\", \"Trout\"]:\n",
    "#         species_dir = class_dir / species_name\n",
    "#         for date_folder in species_dir.iterdir():\n",
    "#             if date_folder.is_dir():\n",
    "#                 date = date_folder.name\n",
    "#                 for image_file in date_folder.glob('*.*'):\n",
    "#                     # Store metadata with each image path\n",
    "#                     item = {\n",
    "#                         \"path\": image_file,\n",
    "#                         \"class\": class_name,\n",
    "#                         \"species\": species_name,\n",
    "#                         \"date\": date\n",
    "#                     }\n",
    "#                     # Assign test data based on specified conditions\n",
    "#                     if (species_name == \"Grayling\" and date == \"Day_35\") or \\\n",
    "#                        (species_name == \"Trout\" and date == \"Day_146\"):\n",
    "#                         test_data.append(item)\n",
    "#                     else:\n",
    "#                         data.append(item)\n",
    "\n",
    "# # Shuffle data for random splitting\n",
    "# random.seed(123)  # For reproducibility\n",
    "# random.shuffle(data)\n",
    "\n",
    "# # Split remaining data into train (85%) and validation (15%)\n",
    "# total_count = len(data)\n",
    "# train_count = int(0.85 * total_count)\n",
    "\n",
    "# train_data = data[:train_count]\n",
    "# valid_data = data[train_count:]\n",
    "\n",
    "# # Convert lists of metadata to DataFrames for easier access\n",
    "# train_df = pd.DataFrame(train_data)\n",
    "# valid_df = pd.DataFrame(valid_data)\n",
    "# test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# # Save metadata DataFrames to CSV files for future use\n",
    "# train_df.to_csv(output_dir / 'train_metadata.csv', index=False)\n",
    "# valid_df.to_csv(output_dir / 'valid_metadata.csv', index=False)\n",
    "# test_df.to_csv(output_dir / 'test_metadata.csv', index=False)\n",
    "\n",
    "# # Function to copy images to output directory with new structure\n",
    "# def copy_images(data_split, target_dir):\n",
    "#     for item in data_split:\n",
    "#         target_class_dir = target_dir / item[\"class\"]\n",
    "#         target_species_dir = target_class_dir / item[\"species\"]\n",
    "#         target_species_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "#         # Copy image to the new directory, preserving original filename\n",
    "#         shutil.copy(item[\"path\"], target_species_dir / item[\"path\"].name)\n",
    "\n",
    "# # Copy images to respective folders\n",
    "# copy_images(train_data, train_dir)\n",
    "# copy_images(valid_data, valid_dir)\n",
    "# copy_images(test_data, test_dir)\n",
    "\n",
    "# # Load the datasets from the new directories\n",
    "# train_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     train_dir,\n",
    "#     image_size=(256, 256),  # Specify your desired image size\n",
    "#     batch_size=32,          # Specify your desired batch size\n",
    "#     seed=123,\n",
    "# )\n",
    "\n",
    "# valid_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     valid_dir,\n",
    "#     image_size=(256, 256),\n",
    "#     batch_size=32,\n",
    "#     seed=123,\n",
    "# )\n",
    "\n",
    "# test_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     test_dir,\n",
    "#     image_size=(256, 256),\n",
    "#     batch_size=32,\n",
    "#     seed=123,\n",
    "# )\n",
    "\n",
    "# train_set.name = 'Training'\n",
    "# valid_set.name = 'Validation'\n",
    "# test_set.name = 'Test'\n",
    "\n",
    "# # Print class names and dataset sizes\n",
    "# class_names = train_set.class_names\n",
    "# print(\"Class names:\", class_names)\n",
    "# print(\"Training dataset size:\", len(train_set))\n",
    "# print(\"Validation dataset size:\", len(valid_set))\n",
    "# print(\"Test dataset size:\", len(test_set))\n",
    "\n",
    "# # Print number of test images\n",
    "# print(\"\\n\",\"Total number of images in the input dataset:\", \"\\n\",\"train + valid:\",len(data), \"\\n\",\"test:\",len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2. Preprocess Data for Baseline and Augmented Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPROCESSING FOR THE BASELINE MODELS:\n",
    "def preprocessing_function(image, label):\n",
    "\n",
    "    num_classes = 2\n",
    "\n",
    "    # Cast the image and label datatypes\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    label = tf.cast(label,tf.int32)\n",
    "\n",
    "    # Normalize the pixel values. Use a float value in the denominator!\n",
    "    image = image / 255.0\n",
    "    # Cast the label to int32 and one-hot encode\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "    # Recast label to Float32\n",
    "    label = tf.cast(label, tf.float32)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "train = train_set.map(preprocessing_function)\n",
    "validation = valid_set.map(preprocessing_function)\n",
    "test = test_set.map(preprocessing_function)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3. Runs for the Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.1 Define Baseline callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CNN_logdir():\n",
    "    time = np.datetime64('now').astype(str)[:-3].replace(':', '-')\n",
    "    run_logdir = os.path.join(os.curdir, \"Final_CNN_logs\", f\"Baseline_run_on_classic_data{time}\") # time goes in the fstring\n",
    "    return run_logdir\n",
    "\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"Baseline_run_on_classic_data.keras\",\n",
    "                                                   save_best_only=True,\n",
    "                                                   monitor='val_loss')\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(get_CNN_logdir())\n",
    "\n",
    "# Let's clear out the backend and set our random seeds.\n",
    "# Consistency is key :)\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(rnd_seed)\n",
    "np.random.seed(rnd_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.2 Build Baseline architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    # Convolution 1\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=7, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPool2D((3,3)),\n",
    "\n",
    "    # Convolution 2\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=5, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "\n",
    "\n",
    "    # Convolution 3\n",
    "    keras.layers.Conv2D(256, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "\n",
    "\n",
    "    # Convolution 4\n",
    "    keras.layers.Conv2D(256, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(2, activation=\"softmax\") #Change the last layer from 5 classes to 2 classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build((None, 256 , 256, 3))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.3 Training the Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "# Adjust timestamp to avoid colons\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%dT%H_%M_%S\")\n",
    "log_dir = f\".\\\\Final_CNN_logs\\\\Baseline_run_on_classic_data{timestamp}\"\n",
    "\n",
    "#For Ubuntu \n",
    "log_dir = Path(f\"Final_CNN_logs/Baseline_run_on_classic_data{timestamp}\")\n",
    "log_dir_str = log_dir.as_posix()\n",
    "\n",
    "# Define TensorBoard callback with corrected log directory path\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "# Now run the model training\n",
    "history = model.fit(train, # Training data generator\n",
    "                    epochs=30,\n",
    "                    validation_data=validation, # Validation data generator\n",
    "                    callbacks=[early_stopping_cb,\n",
    "                               checkpoint_cb,\n",
    "                               tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4. Runs for the Augmented Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4.1 Define callback Augmented Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(rnd_seed)\n",
    "np.random.seed(rnd_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"Augmented_run_on_classic_data.keras\",\n",
    "                                                   save_best_only=True,\n",
    "                                                   monitor='val_loss')\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(get_CNN_logdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4.2 Build Augmented Baseline architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_model = keras.models.Sequential([\n",
    "    #keras.layers.RandomFlip(), # Flip augmentation removed \n",
    "    keras.layers.RandomRotation(0.08), # Rotation Aumentation\n",
    "    #keras.layers.RandomBrightness([0.2,1.0]),\n",
    "    keras.layers.RandomContrast(0.9),\n",
    "    keras.layers.RandomTranslation(-0.08,0.08),\n",
    "    keras.layers.GaussianNoise( 0.1 , seed =42),\n",
    "    # Convolution 1\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=7, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPool2D((3,3)),\n",
    "\n",
    "    # Convolution 2\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=5, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "\n",
    "\n",
    "    # Convolution 3\n",
    "    keras.layers.Conv2D(256, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "\n",
    "\n",
    "    # Convolution 4\n",
    "    keras.layers.Conv2D(256, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(2, activation=\"softmax\") #Change the last layer from 5 classes to 2 classes\n",
    "\n",
    "    # Copy your previous model's layers here\n",
    "])\n",
    "aug_model.build((None, 256 , 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Set a custom learning rate\n",
    "learning_rate = 0.001  # Try different values: 0.0001, 0.001, 0.005, etc.\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "#changed optimizer = \"adam\" to this:\n",
    "aug_model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4.3 Training Augmented Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import datetime\n",
    "\n",
    "# Generate a valid directory path\n",
    "log_dir = f\".\\\\Final_CNN_logs\\\\Augmented_run_on_classic_data{datetime.datetime.now().strftime('%Y-%m-%dT%H-%M-%S')}\"\n",
    "#For Ubuntu\n",
    "log_dir = Path(f\"Final_CNN_logs/Augmented_run_on_classic_data{datetime.datetime.now().strftime('%Y-%m-%dT%H-%M-%S')}\")\n",
    "log_dir_str = log_dir.as_posix()\n",
    "#\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "history = aug_model.fit(train, # Training data generator\n",
    "                    epochs=30,\n",
    "                    validation_data=validation, # Validation data generator\n",
    "                    callbacks=[early_stopping_cb,\n",
    "                               checkpoint_cb,\n",
    "                               tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5. Save the best models for Baseline and Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir())\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(current_directory)\n",
    "model.save('Baseline_run_on_classic_data.h5')\n",
    "aug_model.save('Augmented_run_on_classic_data.h5')\n",
    "\n",
    "# Let's load the models!\n",
    "non_aug_model = keras.models.load_model(r'Baseline_run_on_classic_data.h5')\n",
    "aug_model = keras.models.load_model(r'Augmented_run_on_classic_data.h5')\n",
    "\n",
    "# And test them on the testing dataset\n",
    "non_aug_model.evaluate(test)\n",
    "aug_model.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6. Preprocess for ResNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_function(image, label):\n",
    "    num_classes = 2\n",
    "\n",
    "    # Cast the image and label datatypes\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    label = tf.cast(label,tf.int32)\n",
    "\n",
    "    # Resize the image to (224, 224) for ResNet50\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    \n",
    "    # Normalize the pixel values. Use a float value in the denominator!\n",
    "    image = image / 255.0\n",
    "\n",
    "    # Cast the label to int32 and one-hot encode\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "    # Recast label to Float32\n",
    "    label = tf.cast(label, tf.float32)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "train = train_set.map(preprocessing_function)\n",
    "valid = valid_set.map(preprocessing_function)\n",
    "test = test_set.map(preprocessing_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for images, labels in train.take(1):\n",
    "  print(f'Images shape: {images.numpy().shape} Labels: {labels.numpy().shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.7. Run for ResNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.7.1 Define Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CNN_logdir():\n",
    "    time = np.datetime64('now').astype(str)[:-3].replace(':', '-')\n",
    "    run_logdir = os.path.join(os.curdir, \"Final_CNN_logs\", f\"ResNet_no_weight_run_on_classic_data{time}\") # change \"ResNet_no_weight_run_on_classic_data{time}\" to f\"ResNet_with_weight_run_on_classic_data{time}\" \n",
    "    return run_logdir\n",
    "\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"CNN_ResNet_no_weight_classic_data.keras\", # change \"CNN_ResNet_no_weight_classic_data.keras\" to \"CNN_ResNet_with_weight_classic_data.keras\" \n",
    "                                                   save_best_only=True,\n",
    "                                                   monitor='val_loss')\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(get_CNN_logdir())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.7.2 Import ResNet model with or without weights and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's clear out the backend and set our random seeds.\n",
    "# Consistency is key :)\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(rnd_seed)\n",
    "np.random.seed(rnd_seed)\n",
    "\n",
    "n_classes = 2\n",
    "\n",
    "# Load ResNet50 with no top layers (without classification layers)\n",
    "#base_model = keras.applications.resnet50.ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3)) #Change to Weight or No Weight\n",
    "base_model = keras.applications.resnet50.ResNet50(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
    "model = keras.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Freeze the base model\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = False\n",
    "# base_model.trainable = False\n",
    "\n",
    "inputs = train.map(lambda image, label: (image, label))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, decay=0.01) \n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]) \n",
    "\n",
    "import datetime\n",
    "\n",
    "# Generate a valid directory path\n",
    "\n",
    "log_dir = f\".\\\\Final_CNN_logs\\\\ResNet_no_weight_run_on_classic_data{datetime.datetime.now().strftime('%Y-%m-%dT%H-%M-%S')}\" # change \"ResNet_no_weight_run_on_classic_data{time}\" to f\"ResNet_with_weight_run_on_classic_data{time}\" \n",
    "\n",
    "#For Ubuntu\n",
    "log_dir = Path(f\"Final_CNN_logs/ResNet_no_weight_run_on_classic_data{datetime.datetime.now().strftime('%Y-%m-%dT%H-%M-%S')}\") # change \"ResNet_no_weight_run_on_classic_data{time}\" to f\"ResNet_with_weight_run_on_classic_data{time}\" \n",
    "log_dir_str = log_dir.as_posix()\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "history = model.fit(train, epochs=30, validation_data=valid, callbacks=[early_stopping_cb,checkpoint_cb,tensorboard_cb])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.7.3 Save best ResNet model with or without weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('CNN_ResNet_no_weight_classic_data.h5')\n",
    "#model.save('CNN_ResNet_with_weight_classic_data.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Run on Mask Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. Import Mask Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR MASK DATA ORDERING\n",
    "\n",
    "import numpy as np\n",
    "import pooch\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "rnd_seed = 42\n",
    "rnd_gen = np.random.default_rng(rnd_seed)\n",
    "\n",
    "# Define paths\n",
    "#base_dir = Path(r'C:\\Users\\bapti\\Downloads\\ML_Project\\Copy_full_fish_dataset')\n",
    "base_dir = Path(r'C:\\Users\\bapti\\Downloads\\Mask_creation')\n",
    "#output_dir = Path(r'C:\\Users\\bapti\\Downloads\\ML_Project\\Data_ready')\n",
    "output_dir = Path(r'C:\\Users\\bapti\\Downloads\\Mask_data_ready')\n",
    "train_dir = output_dir / 'Train'\n",
    "valid_dir = output_dir / 'Valid'\n",
    "test_dir = output_dir / 'Test'\n",
    "\n",
    "# Ensure output directories exist\n",
    "for path in [train_dir, valid_dir, test_dir]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Collect all images with metadata\n",
    "data = []\n",
    "test_data = []\n",
    "\n",
    "for class_name in [\"LEFT\", \"RIGHT\"]:\n",
    "    class_dir = base_dir / class_name\n",
    "    for species_name in [\"Grayling\", \"Trout\"]:\n",
    "        species_dir = class_dir / species_name\n",
    "        for date_folder in species_dir.iterdir():\n",
    "            if date_folder.is_dir():\n",
    "                date = date_folder.name\n",
    "                for image_file in date_folder.glob('*.*'):\n",
    "                    # Store metadata with each image path\n",
    "                    item = {\n",
    "                        \"path\": image_file,\n",
    "                        \"class\": class_name,\n",
    "                        \"species\": species_name,\n",
    "                        \"date\": date\n",
    "                    }\n",
    "                    # Assign test data based on specified conditions\n",
    "                    if (species_name == \"Grayling\" and date == \"Day_35\") or \\\n",
    "                       (species_name == \"Trout\" and date == \"Day_146\"):\n",
    "                        test_data.append(item)\n",
    "                    else:\n",
    "                        data.append(item)\n",
    "\n",
    "# Shuffle data for random splitting\n",
    "random.seed(123)  # For reproducibility\n",
    "random.shuffle(data)\n",
    "\n",
    "# Split remaining data into train (85%) and validation (15%)\n",
    "total_count = len(data)\n",
    "train_count = int(0.85 * total_count)\n",
    "\n",
    "train_data = data[:train_count]\n",
    "valid_data = data[train_count:]\n",
    "\n",
    "# Convert lists of metadata to DataFrames for easier access\n",
    "train_df = pd.DataFrame(train_data)\n",
    "valid_df = pd.DataFrame(valid_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# Save metadata DataFrames to CSV files for future use\n",
    "train_df.to_csv(output_dir / 'train_metadata.csv', index=False)\n",
    "valid_df.to_csv(output_dir / 'valid_metadata.csv', index=False)\n",
    "test_df.to_csv(output_dir / 'test_metadata.csv', index=False)\n",
    "\n",
    "# Function to copy images to output directory with new structure\n",
    "def copy_images(data_split, target_dir):\n",
    "    for item in data_split:\n",
    "        target_class_dir = target_dir / item[\"class\"]\n",
    "        target_species_dir = target_class_dir / item[\"species\"]\n",
    "        target_species_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Copy image to the new directory, preserving original filename\n",
    "        shutil.copy(item[\"path\"], target_species_dir / item[\"path\"].name)\n",
    "\n",
    "# Copy images to respective folders\n",
    "copy_images(train_data, train_dir)\n",
    "copy_images(valid_data, valid_dir)\n",
    "copy_images(test_data, test_dir)\n",
    "\n",
    "# Load the datasets from the new directories\n",
    "train_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(256, 256),  # Specify your desired image size\n",
    "    batch_size=32,          # Specify your desired batch size\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "valid_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    valid_dir,\n",
    "    image_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "test_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "train_set.name = 'Training'\n",
    "valid_set.name = 'Validation'\n",
    "test_set.name = 'Test'\n",
    "\n",
    "# Print class names and dataset sizes\n",
    "class_names = train_set.class_names\n",
    "print(\"Class names:\", class_names)\n",
    "print(\"Training dataset size:\", len(train_set))\n",
    "print(\"Validation dataset size:\", len(valid_set))\n",
    "print(\"Test dataset size:\", len(test_set))\n",
    "\n",
    "# Print number of test images\n",
    "print(\"\\n\",\"Total number of images in the input dataset:\", \"\\n\",\"train + valid:\",len(data), \"\\n\",\"test:\",len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #FOLLOWING CODE FOR CLASSIC DATA WITHOUT ORDERING (IF THE ORDERING HAS ALREADY BEEN DONE WITH THE ABOVE CELL)\n",
    "\n",
    "# #FOR CLASSIC DATA WITHOUT ORDERING\n",
    "# from PIL import Image\n",
    "# import tensorflow as tf\n",
    "# import os\n",
    "# import random\n",
    "# import shutil\n",
    "# from pathlib import Path\n",
    "# import pandas as pd\n",
    "\n",
    "# # Define paths\n",
    "# #base_dir = Path(r'C:\\Users\\bapti\\Downloads\\ML_Project\\Copy_full_fish_dataset')\n",
    "# base_dir = Path(r'C:\\Users\\bapti\\Downloads\\Mask_creation')\n",
    "# #output_dir = Path(r'C:\\Users\\bapti\\Downloads\\ML_Project\\Data_ready')\n",
    "# output_dir = Path(r'C:\\Users\\bapti\\Downloads\\Mask_data_ready')\n",
    "# #For Ubuntu: \n",
    "# base_dir = Path('/mnt/c/Users/bapti/Downloads/Mask_creation')\n",
    "# output_dir = Path('/mnt/c/Users/bapti/Downloads/Mask_data_ready')\n",
    "\n",
    "# train_dir = output_dir / 'Train'\n",
    "# valid_dir = output_dir / 'Valid'\n",
    "# test_dir = output_dir / 'Test'\n",
    "\n",
    "# # Ensure output directories exist\n",
    "# for path in [train_dir, valid_dir, test_dir]:\n",
    "#     path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Collect all images with metadata\n",
    "# data = []\n",
    "# test_data = []\n",
    "\n",
    "# for class_name in [\"LEFT\", \"RIGHT\"]:\n",
    "#     class_dir = base_dir / class_name\n",
    "#     for species_name in [\"Grayling\", \"Trout\"]:\n",
    "#         species_dir = class_dir / species_name\n",
    "#         for date_folder in species_dir.iterdir():\n",
    "#             if date_folder.is_dir():\n",
    "#                 date = date_folder.name\n",
    "#                 for image_file in date_folder.glob('*.*'):\n",
    "#                     # Store metadata with each image path\n",
    "#                     item = {\n",
    "#                         \"path\": image_file,\n",
    "#                         \"class\": class_name,\n",
    "#                         \"species\": species_name,\n",
    "#                         \"date\": date\n",
    "#                     }\n",
    "#                     # Assign test data based on specified conditions\n",
    "#                     if (species_name == \"Grayling\" and date == \"Day_35\") or \\\n",
    "#                        (species_name == \"Trout\" and date == \"Day_146\"):\n",
    "#                         test_data.append(item)\n",
    "#                     else:\n",
    "#                         data.append(item)\n",
    "\n",
    "# # Shuffle data for random splitting\n",
    "# random.seed(123)  # For reproducibility\n",
    "# random.shuffle(data)\n",
    "\n",
    "# # Split remaining data into train (85%) and validation (15%)\n",
    "# total_count = len(data)\n",
    "# train_count = int(0.85 * total_count)\n",
    "\n",
    "# train_data = data[:train_count]\n",
    "# valid_data = data[train_count:]\n",
    "\n",
    "# # Load the datasets from the new directories\n",
    "# train_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     train_dir,\n",
    "#     image_size=(256, 256),  # Specify your desired image size\n",
    "#     batch_size=32,          # Specify your desired batch size\n",
    "#     seed=123,\n",
    "# )\n",
    "\n",
    "# valid_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     valid_dir,\n",
    "#     image_size=(256, 256),\n",
    "#     batch_size=32,\n",
    "#     seed=123,\n",
    "# )\n",
    "\n",
    "# test_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     test_dir,\n",
    "#     image_size=(256, 256),\n",
    "#     batch_size=32,\n",
    "#     seed=123,\n",
    "# )\n",
    "\n",
    "# train_set.name = 'Training'\n",
    "# valid_set.name = 'Validation'\n",
    "# test_set.name = 'Test'\n",
    "\n",
    "# # Print class names and dataset sizes\n",
    "# class_names = train_set.class_names\n",
    "# print(\"Class names:\", class_names)\n",
    "# print(\"Training dataset size:\", len(train_set))\n",
    "# print(\"Validation dataset size:\", len(valid_set))\n",
    "# print(\"Test dataset size:\", len(test_set))\n",
    "\n",
    "# # Print number of test images\n",
    "# print(\"\\n\",\"Total number of images in the input dataset:\", \"\\n\",\"train + valid:\",len(data), \"\\n\",\"test:\",len(test_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Preprocess for ResNet models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocessing_function(image, label):\n",
    "    # We're going to hard code the image size we want to use. We can define this\n",
    "    # with a lambda function, but we won't really need to change this and it's\n",
    "    # more trouble than it's worth for us right now :)\n",
    "    # image_size = 128\n",
    "    num_classes = 2\n",
    "\n",
    "    # Cast the image and label datatypes\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    label = tf.cast(label,tf.int32)\n",
    "\n",
    "    # Resize the image to (224, 224) for ResNet50\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    \n",
    "    # Normalize the pixel values. Use a float value in the denominator!\n",
    "    image = image / 255.0\n",
    "\n",
    "    # Resize the image\n",
    "    # image = tf.image.resize(image, ( image_size,  image_size))\n",
    "\n",
    "    # Cast the label to int32 and one-hot encode\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "    # Recast label to Float32\n",
    "    label = tf.cast(label, tf.float32)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "train = train_set.map(preprocessing_function)\n",
    "validation = valid_set.map(preprocessing_function)\n",
    "test = test_set.map(preprocessing_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3. Run for ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.1 Define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CNN_logdir():\n",
    "    time = np.datetime64('now').astype(str)[:-3].replace(':', '-')\n",
    "    run_logdir = os.path.join(os.curdir, \"Final_CNN_logs\", f\"ResNet_no_weight_run_on_mask_data{time}\") # Replace \"ResNet_no_weight_run_on_mask_data{time}\" with \"ResNet_with_weight_run_on_mask_data{time}\" for training with weights\n",
    "    return run_logdir\n",
    "\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"CNN_ResNet_no_weight_mask_data.keras\", #Replace \"CNN_ResNet_no_weight_mask_data.keras\" with \"CNN_ResNet_with_weight_mask_data.keras\" \n",
    "                                                   save_best_only=True,\n",
    "                                                   monitor='val_loss')\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(get_CNN_logdir())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.2 Import ResNet model with or without weights and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's clear out the backend and set our random seeds.\n",
    "# Consistency is key :)\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(rnd_seed)\n",
    "np.random.seed(rnd_seed)\n",
    "\n",
    "n_classes = 2\n",
    "\n",
    "# Load ResNet50 with no top layers (without classification layers)\n",
    "base_model = keras.applications.resnet50.ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
    "model = keras.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Freeze the base model\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = False\n",
    "# base_model.trainable = False\n",
    "\n",
    "inputs = train.map(lambda image, label: (image, label))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, decay=0.01) \n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]) \n",
    "\n",
    "import datetime\n",
    "\n",
    "# Generate a valid directory path\n",
    "\n",
    "log_dir = f\".\\\\Final_CNN_logs\\\\ResNet_no_weight_run_on_mask_data{datetime.datetime.now().strftime('%Y-%m-%dT%H-%M-%S')}\" # Replace \"ResNet_no_weight_run_on_mask_data\" with \"ResNet_with_weight_run_on_mask_data\" for training with weights\n",
    "#For Ubuntu\n",
    "log_dir = Path(f\"Final_CNN_logs/ResNet_no_weight_run_on_mask_data{datetime.datetime.now().strftime('%Y-%m-%dT%H-%M-%S')}\") # Replace \"ResNet_no_weight_run_on_mask_data\" with \"ResNet_with_weight_run_on_mask_data\" for training with weights\n",
    "log_dir_str = log_dir.as_posix()\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "history = model.fit(train, epochs=30, validation_data=valid, callbacks=[early_stopping_cb,checkpoint_cb,tensorboard_cb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.3 Save ResNet models with and without weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('CNN_ResNet_no_weight_mask_data.h5')\n",
    "#model.save('CNN_ResNet_with_weight_mask_data.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.4 Optional, Load the models and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir())\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(current_directory)\n",
    "\n",
    "# #aug_model = keras.models.load_model('path/to/your/directory/CNN_augmented.h5')\n",
    "classic_model = keras.models.load_model(r'CNN_ResNet_no_weight_mask_data.keras')\n",
    "mask_model = keras.models.load_model(r'CNN_ResNet_no_weight_classic_data.keras')\n",
    "\n",
    "# And test them on the testing dataset\n",
    "classic_model.evaluate(test)\n",
    "mask_model.evaluate(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To visualize Model performance on Tensorboard:\n",
    "#%tensorboard --logdir=./Final_CNN_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Preprocess for Baseline and Augmented Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# BASELINE RUN ON MASK DATA:\n",
    "\n",
    " #PREPROCESSING FOR THE BASELINE MODELS:\n",
    "def preprocessing_function(image, label):\n",
    "    num_classes = 2\n",
    "\n",
    "    # Cast the image and label datatypes\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    label = tf.cast(label,tf.int32)\n",
    "\n",
    "    # Normalize the pixel values. Use a float value in the denominator!\n",
    "    image = image / 255.0\n",
    "\n",
    "    # Cast the label to int32 and one-hot encode\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "    # Recast label to Float32\n",
    "    label = tf.cast(label, tf.float32)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "train = train_set.map(preprocessing_function)\n",
    "validation = valid_set.map(preprocessing_function)\n",
    "test = test_set.map(preprocessing_function)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5. Runs for Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5.1 Define callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CNN_logdir():\n",
    "    time = np.datetime64('now').astype(str)[:-3].replace(':', '-')\n",
    "    run_logdir = os.path.join(os.curdir, \"Final_CNN_logs\", f\"Baseline_run_on_mask_data{time}\") # time goes in the fstring\n",
    "    return run_logdir\n",
    "\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"Baseline_run_on_mask_data.keras\",\n",
    "                                                   save_best_only=True,\n",
    "                                                   monitor='val_loss')\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(get_CNN_logdir())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5.2 Build Baseline Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's clear out the backend and set our random seeds.\n",
    "# Consistency is key :)\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(rnd_seed)\n",
    "np.random.seed(rnd_seed)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    # Convolution 1\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=7, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPool2D((3,3)),\n",
    "\n",
    "    # Convolution 2\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=5, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "\n",
    "\n",
    "    # Convolution 3\n",
    "    keras.layers.Conv2D(256, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "\n",
    "\n",
    "    # Convolution 4\n",
    "    keras.layers.Conv2D(256, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(2, activation=\"softmax\") #Change the last layer from 5 classes to 2 classes\n",
    "])\n",
    "\n",
    "model.build((None, 256 , 256, 3))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5.3 train Baseline Architecure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust timestamp to avoid colons\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%dT%H_%M_%S\")\n",
    "log_dir = f\".\\\\Final_CNN_logs\\\\Baseline_run_on_mask_data{timestamp}\"\n",
    "#For Ubuntu\n",
    "log_dir = Path(f\"Final_CNN_logs/Baseline_run_on_mask_data{datetime.datetime.now().strftime('%Y-%m-%dT%H-%M-%S')}\")\n",
    "log_dir_str = log_dir.as_posix()\n",
    "\n",
    "# Define TensorBoard callback with corrected log directory path\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "# Now run the model training\n",
    "history = model.fit(train, # Training data generator\n",
    "                    epochs=30,\n",
    "                    validation_data=validation, # Validation data generator\n",
    "                    callbacks=[early_stopping_cb,\n",
    "                               checkpoint_cb,\n",
    "                               tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6. Runs for Augmented Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6.1 Define callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CNN_logdir():\n",
    "    time = np.datetime64('now').astype(str)[:-3].replace(':', '-')\n",
    "    run_logdir = os.path.join(os.curdir, \"Final_CNN_logs\", f\"Augmented_run_on_mask_data{time}\") # time goes in the fstring\n",
    "    return run_logdir\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"Augmnented_run_on_mask_data.keras\",\n",
    "                                                   save_best_only=True,\n",
    "                                                   monitor='val_loss')\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(get_CNN_logdir())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6.2 Build Augmented Baseline Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUGMENTED RUN ON MASK DATA\n",
    "\n",
    "aug_model = keras.models.Sequential([\n",
    "    #keras.layers.RandomFlip(), # Flip augmentation removed \n",
    "    keras.layers.RandomRotation(0.08), # Rotation Aumentation\n",
    "    #keras.layers.RandomBrightness([0.2,1.0]),\n",
    "    keras.layers.RandomContrast(0.9),\n",
    "    keras.layers.RandomTranslation(-0.08,0.08),\n",
    "    # Convolution 1\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=7, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPool2D((3,3)),\n",
    "\n",
    "    # Convolution 2\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=5, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "\n",
    "\n",
    "    # Convolution 3\n",
    "    keras.layers.Conv2D(256, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "\n",
    "\n",
    "    # Convolution 4\n",
    "    keras.layers.Conv2D(256, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(2, activation=\"softmax\") #Change the last layer from 5 classes to 2 classes\n",
    "\n",
    "    # Copy your previous model's layers here\n",
    "])\n",
    "aug_model.build((None, 256 , 256, 3))\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set a custom learning rate\n",
    "learning_rate = 0.001  # Try different values: 0.0001, 0.001, 0.005, etc.\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "#changed optimizer = \"adam\" to this:\n",
    "aug_model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6.3 Train Augmented baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Generate a valid directory path\n",
    "log_dir = f\".\\\\Final_CNN_logs\\\\Augmented_run_on_mask_data{datetime.datetime.now().strftime('%Y-%m-%dT%H-%M-%S')}\"\n",
    "#For Ubuntu\n",
    "log_dir = Path(f\"Final_CNN_logs/Augmented_run_on_mask_data{datetime.datetime.now().strftime('%Y-%m-%dT%H-%M-%S')}\")\n",
    "log_dir_str = log_dir.as_posix()\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "history = aug_model.fit(train, # Training data generator\n",
    "                    epochs=30,\n",
    "                    validation_data=validation, # Validation data generator\n",
    "                    callbacks=[early_stopping_cb,\n",
    "                               checkpoint_cb,\n",
    "                               tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.7 Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir())\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(current_directory)\n",
    "model.save('Baseline_run_on_mask_data.h5')\n",
    "aug_model.save('Augmented_run_on_mask_data.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.8 Optional Load the models and evaluate their performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_aug_model = keras.models.load_model(r'Baseline_run_on_mask_data.h5')\n",
    "aug_model = keras.models.load_model(r'Augmented_run_on_mask_data.h5')\n",
    "\n",
    "# And test them on the testing dataset\n",
    "# non_aug_model.evaluate(test)\n",
    "# aug_model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "#\"Test the model on new data:\n",
    "\n",
    "##Test on \"mask data\" (if trained on classic data)\n",
    "#data_to_test = r\"C:\\Users\\bapti\\Downloads\\ML_Project\\Data_ready\\Test\"\n",
    "##Test on \"classic data\" (if trained on mask data)\n",
    "\n",
    "path_data_to_test = r\"C:\\Users\\bapti\\Downloads\\Mask_data_ready\\Test\"\n",
    "#For UBUNTU:\n",
    "#On mask\n",
    "path_data_to_test = Path('/mnt/c/Users/bapti/Downloads/Mask_data_ready/Test')\n",
    "#On classic\n",
    "path_data_to_test = Path('/mnt/c/Users/bapti/Downloads/ML_Project/Data_ready/Test')\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    path_data_to_test,\n",
    "    image_size=(256, 256), #CHANGE RESIER TO SIZE ACCEPTED BY MODEL\n",
    "    batch_size=16,\n",
    "    shuffle=False  # Do not shuffle if the dataset order matters\n",
    ")\n",
    "def one_hot_encode_labels(images, labels):\n",
    "    labels = tf.one_hot(labels, depth=2)\n",
    "    return images, labels\n",
    "test_dataset = test_dataset.map(one_hot_encode_labels)\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "# #Which model?\n",
    "# model_ready =  keras.models.load_model(r'CNN_ResNet_classic_data.h5')\n",
    "# model_ready =  keras.models.load_model(r'CNN_ResNet_mask_data.h5')\n",
    "model_ready = keras.models.load_model(r'Baseline_run_on_mask_data.h5')\n",
    "\n",
    "# Evaluate the augmented model\n",
    "aug_results = model_ready.evaluate(test) \n",
    "print(\"Augmented Model - Test Loss:\", aug_results[0])\n",
    "print(\"Augmented Model - Test Accuracy:\", aug_results[1])\n",
    "\n",
    "# Evaluate the non-augmented model\n",
    "non_aug_results = model.evaluate(test_dataset)\n",
    "print(\"Non-Augmented Model - Test Loss:\", non_aug_results[0])\n",
    "print(\"Non-Augmented Model - Test Accuracy:\", non_aug_results[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATE MODELS ON TEST SETS:\n",
    "\n",
    "baseline_model_ready_classic = keras.models.load_model(r'Baseline_run_on_classic_data.h5')\n",
    "baseline_model_ready_mask = keras.models.load_model(r'Baseline_run_on_mask_data.h5')\n",
    "Augmented_model_ready_classic = keras.models.load_model(r'Augmented_run_on_classic_data.h5')\n",
    "Augmented_model_ready_mask = keras.models.load_model(r'Augmented_run_on_mask_data.h5')\n",
    "ResNet_no_weight_model_ready_classic = keras.models.load_model(r'CNN_ResNet_no_weight_classic_data.h5')\n",
    "ResNet_no_weight_model_ready_mask = keras.models.load_model(r'CNN_ResNet_no_weight_mask_data.h5')\n",
    "ResNet_weight_model_ready_classic = keras.models.load_model(r'CNN_ResNet_classic_data.h5')\n",
    "ResNet_weight_model_ready_mask = keras.models.load_model(r'CNN_ResNet_mask_data.h5')\n",
    "\n",
    "\n",
    "#PREPROCESSING FOR THE BASELINE MODELS:\n",
    "def preprocessing_function_256(image, label):\n",
    "    num_classes = 2\n",
    "\n",
    "    # Cast the image and label datatypes\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    label = tf.cast(label,tf.int32)\n",
    "\n",
    "    # Normalize the pixel values. Use a float value in the denominator!\n",
    "    image = image / 255.0\n",
    "\n",
    "    # Cast the label to int32 and one-hot encode\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "    # Recast label to Float32\n",
    "    label = tf.cast(label, tf.float32)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "#PREPROCESSING FOR THE RESNET:\n",
    "\n",
    "def preprocessing_function_224(image, label):\n",
    "\n",
    "    num_classes = 2\n",
    "\n",
    "    # Cast the image and label datatypes\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    label = tf.cast(label,tf.int32)\n",
    "\n",
    "    # Resize the image to (224, 224) for ResNet50\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    \n",
    "    # Normalize the pixel values. Use a float value in the denominator!\n",
    "    image = image / 255.0\n",
    "\n",
    "    # Cast the label to int32 and one-hot encode\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "    # Recast label to Float32\n",
    "    label = tf.cast(label, tf.float32)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "\n",
    "test_256 = test_set.map(preprocessing_function_256)\n",
    "test_224 = test_set.map(preprocessing_function_224)\n",
    "\n",
    "baseline_model_ready_classic.evaluate(test_256) \n",
    "baseline_model_ready_mask.evaluate(test_256) \n",
    "Augmented_model_ready_classic.evaluate(test_256) \n",
    "Augmented_model_ready_mask.evaluate(test_256) \n",
    "ResNet_no_weight_model_ready_classic.evaluate(test_224) \n",
    "ResNet_no_weight_model_ready_mask.evaluate(test_224) \n",
    "ResNet_weight_model_ready_classic.evaluate(test_224) \n",
    "ResNet_weight_model_ready_mask.evaluate(test_224) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Salency Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First test of Salency maps, kept for personnal interest. You may want to run it by curiosity\n",
    "\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras.models import load_model\n",
    "# from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "# from tf_keras_vis.saliency import Saliency\n",
    "# from tf_keras_vis.utils import normalize\n",
    "# from tf_keras_vis.utils.scores import CategoricalScore\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Load your model\n",
    "# # model_ready = load_model(r'CNN_ResNet_classic_data.h5')\n",
    "# # model_ready =  keras.models.load_model(r'CNN_ResNet_classic_data.h5')\n",
    "# # model_ready =  keras.models.load_model(r'CNN_ResNet_classic_data.h5')\n",
    "# # model_ready =  keras.models.load_model(r'CNN_ResNet_mask_data.h5')\n",
    "# model_ready = keras.models.load_model(r'Baseline_run_on_mask_data.h5')\n",
    "# # Prepare the image\n",
    "# path_data_to_test = r\"C:\\Users\\bapti\\Downloads\\Mask_data_ready\\Test\\LEFT\\Trout\\IMG_7946_processed.jpg\"\n",
    "\n",
    "# #For UBUNTU:\n",
    "# path_data_to_test = Path('/mnt/c/Users/bapti/Downloads/Mask_data_ready/Test/LEFT/Trout/IMG_7946_processed.jpg')\n",
    "# # path_data_to_test = Path('/mnt/c/Users/bapti/Downloads/ML_Project/Data_ready/Test/LEFT/Trout/IMG_7946.jpg')\n",
    "# print(model_ready.input_shape)\n",
    "\n",
    "# img = load_img(path_data_to_test, target_size=(256, 256)) # CHANGE THE RESIZE FOR THE CORECT MODEL + HAVE THE RIGHT PREPROCESSING FUNCTION\n",
    "# x = img_to_array(img)  # Convert to numpy array\n",
    "# x = x.reshape((1,) + x.shape)  # Add batch dimension\n",
    "# x = x / 255.0  # Normalize image data if your model expects normalized inputs\n",
    "\n",
    "# # Convert the last activation layer to linear\n",
    "# model_ready.layers[-1].activation = None  # For TensorFlow 2.x compatibility\n",
    "\n",
    "# # Define the class index you want to visualize\n",
    "# class_index = 0  # Change this to match your target class index\n",
    "# score = CategoricalScore([class_index])\n",
    "\n",
    "# # Create Saliency object\n",
    "# saliency = Saliency(model_ready, clone=False)\n",
    "\n",
    "# # Generate saliency map\n",
    "# saliency_map = saliency(score, x, smooth_samples=20, smooth_noise=0.2)\n",
    "# saliency_map = normalize(saliency_map)  # Normalize values for visualization\n",
    "\n",
    "# # Plot saliency map\n",
    "# plt.figure(figsize=(5, 4))\n",
    "# plt.imshow(saliency_map[0], cmap='hot')\n",
    "# plt.axis('off')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Load the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tf_keras_vis.saliency import Saliency\n",
    "from tf_keras_vis.utils import normalize\n",
    "from tf_keras_vis.utils.scores import CategoricalScore\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Define the base directory for the test data\n",
    "base_dir = Path('/mnt/c/Users/bapti/Downloads/ML_Project/Data_ready/Test')\n",
    "#base_dir = Path('/mnt/c/Users/bapti/Downloads/Mask_data_ready/Test')\n",
    "\n",
    "# Initialize an empty list to hold test data\n",
    "test_data = []\n",
    "\n",
    "# Check if the base directory exists\n",
    "if not base_dir.exists():\n",
    "    raise ValueError(f\"Base directory does not exist: {base_dir}\")\n",
    "\n",
    "# Loop through the 'LEFT' and 'RIGHT' directories\n",
    "for class_name in [\"LEFT\", \"RIGHT\"]:\n",
    "    class_dir = base_dir / class_name\n",
    "    print(f\"Checking class directory: {class_dir}\")\n",
    "    \n",
    "    if not class_dir.exists():\n",
    "        print(f\"Class directory does not exist: {class_dir}\")\n",
    "        continue\n",
    "\n",
    "    for species_name in [\"Grayling\", \"Trout\"]:\n",
    "        species_dir = class_dir / species_name\n",
    "        print(f\"Checking species directory: {species_dir}\")\n",
    "        \n",
    "        if not species_dir.exists():\n",
    "            print(f\"Species directory does not exist: {species_dir}\")\n",
    "            continue\n",
    "        \n",
    "        # List all image files in the directory\n",
    "        for image_file in species_dir.glob('*.*'):\n",
    "            if image_file.is_file():  # Ensure it's an actual file\n",
    "                item = {\n",
    "                    \"path\": image_file,\n",
    "                    \"class\": class_name,\n",
    "                    \"species\": species_name\n",
    "                }\n",
    "                test_data.append(item)\n",
    "\n",
    "# Check if test_data is populated\n",
    "print(f\"Number of test data items: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Load the model (you may manualy chose whichever you prefer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_ready = keras.models.load_model(r'CNN_ResNet_classic_data.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Preprocess the data (you may change adapt the target size to 224 for ResNet and 256 for Baseline and Augmented baseline models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure test data is populated correctly\n",
    "if len(test_data) == 0:\n",
    "    raise ValueError(\"Test data is empty. Please check the data loading process.\")\n",
    "\n",
    "# Image preprocessing function\n",
    "def image_path_to_array(image_path, target_size=(224, 224)):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize(target_size)  # Resize to the target size\n",
    "    image_array = np.array(image)  # Convert to numpy array\n",
    "    image_array = image_array / 255.0  # Normalize to [0, 1]\n",
    "    return image_array\n",
    "\n",
    "# Get the actual images and their corresponding filenames\n",
    "test_images = np.array([image_path_to_array(item[\"path\"]) for item in test_data])  # Load images and convert to arrays\n",
    "print(f\"Shape of test_images before reshape: {test_images.shape}\")\n",
    "\n",
    "# Ensure the test_images are in the correct shape (num_samples, 256, 256, 3)\n",
    "test_images = test_images.reshape(-1, 224, 224, 3)  # Explicitly reshape\n",
    "print(f\"Shape of test_images after reshape: {test_images.shape}\")\n",
    "\n",
    "filenames = [item[\"path\"].name for item in test_data]  # Extract filenames for reference\n",
    "\n",
    "# Convert class labels to 0 (LEFT) and 1 (RIGHT)\n",
    "test_labels = [1 if item[\"class\"] == \"RIGHT\" else 0 for item in test_data]\n",
    "print(f\"Number of test labels: {len(test_labels)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 Get the best and worst predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model predictions\n",
    "predictions = model_ready.predict(test_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)  # Convert to class indices\n",
    "\n",
    "# Check if predicted_classes has the correct shape\n",
    "print(f\"Shape of predicted_classes: {predicted_classes.shape}\")\n",
    "if len(predicted_classes) != len(test_labels):\n",
    "    raise ValueError(f\"Mismatch between predicted classes and test labels. \"\n",
    "                     f\"Predicted: {len(predicted_classes)}, Labels: {len(test_labels)}\")\n",
    "\n",
    "# Correct and wrong predictions\n",
    "correct_preds = predicted_classes == test_labels\n",
    "wrong_preds = ~correct_preds\n",
    "\n",
    "# Calculate best and worst confidence\n",
    "best_idx = None\n",
    "worst_idx = None\n",
    "\n",
    "if np.any(correct_preds):\n",
    "    best_confidence = predictions[correct_preds, predicted_classes[correct_preds]]\n",
    "    global_correct_indices = np.where(correct_preds)[0]\n",
    "    best_idx = global_correct_indices[np.argmax(best_confidence)]\n",
    "else:\n",
    "    print(\"No correct predictions found.\")\n",
    "\n",
    "if np.any(wrong_preds):\n",
    "    worst_confidence = predictions[wrong_preds, predicted_classes[wrong_preds]]\n",
    "    global_wrong_indices = np.where(wrong_preds)[0]\n",
    "    worst_idx = global_wrong_indices[np.argmin(worst_confidence)]\n",
    "else:\n",
    "    print(\"No wrong predictions found.\")\n",
    "\n",
    "\n",
    "# Define class mapping\n",
    "class_mapping = {0: \"LEFT\", 1: \"RIGHT\"}\n",
    "\n",
    "# Display best and worst prediction details\n",
    "if best_idx is not None:\n",
    "    best_image = test_images[best_idx]\n",
    "    best_label = test_labels[best_idx]\n",
    "    best_filename = filenames[best_idx]\n",
    "    best_pred_class = predicted_classes[best_idx]\n",
    "    best_pred_value = predictions[best_idx][best_pred_class]\n",
    "\n",
    "    print(f\"Best Prediction Details:\")\n",
    "    print(f\"Index: {best_idx}, True Label: {class_mapping[best_label]}, Predicted Class: {class_mapping[best_pred_class]}\")\n",
    "    print(f\"Confidence: {best_pred_value:.4f}, Filename: {best_filename}\")\n",
    "\n",
    "if worst_idx is not None:\n",
    "    worst_image = test_images[worst_idx]\n",
    "    worst_label = test_labels[worst_idx]\n",
    "    worst_filename = filenames[worst_idx]\n",
    "    worst_pred_class = predicted_classes[worst_idx]\n",
    "    worst_pred_value = predictions[worst_idx][worst_pred_class]\n",
    "\n",
    "    print(f\"Worst Prediction Details:\")\n",
    "    print(f\"Index: {worst_idx}, True Label: {class_mapping[worst_label]}, Predicted Class: {class_mapping[worst_pred_class]}\")\n",
    "    print(f\"Confidence: {worst_pred_value:.4f}, Filename: {worst_filename}\")\n",
    "\n",
    "# Find all indices with the highest confidence among correct predictions (best case)\n",
    "if np.any(correct_preds):\n",
    "    best_confidence = predictions[correct_preds, predicted_classes[correct_preds]]\n",
    "    global_correct_indices = np.where(correct_preds)[0]\n",
    "    best_idx = global_correct_indices[np.argmax(best_confidence)]\n",
    "    # Find indices where confidence matches the highest value\n",
    "    duplicate_best_indices = global_correct_indices[best_confidence == max_confidence]\n",
    "    \n",
    "    # Print the number of \"best\" predictions\n",
    "    num_best_predictions = len(duplicate_best_indices)\n",
    "    print(f\"Number of best predictions with the highest confidence ({max_confidence:.4f}): {num_best_predictions}\")\n",
    "    \n",
    "    # Optional: Print their details if needed\n",
    "    if num_best_predictions > 1:\n",
    "        print(\"Details of the best predictions:\")\n",
    "        for idx in duplicate_best_indices:\n",
    "            print(f\" - Filename: {filenames[idx]}, True Label: {class_mapping[test_labels[idx]]}, \"\n",
    "                  f\"Predicted: {class_mapping[predicted_classes[idx]]}\")\n",
    "else:\n",
    "    print(\"No correct predictions found to determine 'best' cases.\")\n",
    "    # Check for duplicates\n",
    "    max_confidence = np.max(best_confidence)\n",
    "    duplicate_best_indices = global_correct_indices[best_confidence == max_confidence]\n",
    "    \n",
    "    if len(duplicate_best_indices) > 1:\n",
    "        print(f\"Multiple best predictions found with the same confidence ({max_confidence:.4f}):\")\n",
    "        for idx in duplicate_best_indices:\n",
    "            print(f\" - Filename: {filenames[idx]}, True Label: {class_mapping[test_labels[idx]]}, \"\n",
    "                  f\"Predicted: {class_mapping[predicted_classes[idx]]}\")\n",
    "    else:\n",
    "        print(f\"No duplicate best predictions found.\")\n",
    "\n",
    "# Find all indices with the lowest confidence among incorrect predictions (worst case)\n",
    "if np.any(wrong_preds):\n",
    "    worst_confidence = predictions[wrong_preds, predicted_classes[wrong_preds]]\n",
    "    global_wrong_indices = np.where(wrong_preds)[0]\n",
    "    worst_idx = global_wrong_indices[np.argmin(worst_confidence)]\n",
    "    \n",
    "    # Check for duplicates\n",
    "    min_confidence = np.min(worst_confidence)\n",
    "    duplicate_worst_indices = global_wrong_indices[worst_confidence == min_confidence]\n",
    "    \n",
    "    if len(duplicate_worst_indices) > 1:\n",
    "        print(f\"Multiple worst predictions found with the same confidence ({min_confidence:.4f}):\")\n",
    "        for idx in duplicate_worst_indices:\n",
    "            print(f\" - Filename: {filenames[idx]}, True Label: {class_mapping[test_labels[idx]]}, \"\n",
    "                  f\"Predicted: {class_mapping[predicted_classes[idx]]}\")\n",
    "    else:\n",
    "        print(f\"No duplicate worst predictions found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5 Plot the Saliency maps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to plot saliency map\n",
    "def plot_saliency_map(image, model, class_index, smooth_samples=20, smooth_noise=0.2):\n",
    "    x = image.reshape((1,) + image.shape)  # Add batch dimension\n",
    "    \n",
    "    # Ensure normalization\n",
    "    if x.max() > 1:\n",
    "        x = x / 255.0  # Normalize if required\n",
    "    \n",
    "    model.layers[-1].activation = None  # Set the last layer activation to linear for saliency\n",
    "    \n",
    "    score = CategoricalScore([class_index])\n",
    "    saliency = Saliency(model, clone=False)\n",
    "    \n",
    "    saliency_map = saliency(score, x, smooth_samples=smooth_samples, smooth_noise=smooth_noise)\n",
    "    saliency_map = normalize(saliency_map)  # Normalize for visualization\n",
    "    \n",
    "    # Rescale and prepare for visualization\n",
    "    saliency_map_rescaled = (saliency_map[0] - saliency_map[0].min()) / (saliency_map[0].max() - saliency_map[0].min())\n",
    "    saliency_map_rescaled = np.clip(saliency_map_rescaled * 1.5, 0, 1)\n",
    "    saliency_map_rescaled = np.uint8(255 * saliency_map_rescaled)\n",
    "    \n",
    "    # Create a red-highlighted colormap\n",
    "    saliency_colormap = np.zeros((*saliency_map_rescaled.shape, 3), dtype=np.uint8)\n",
    "    saliency_colormap[..., 0] = saliency_map_rescaled\n",
    "    \n",
    "    # Original image preparation\n",
    "    original_image = np.clip(x[0], 0, 1)  # Clamp values to [0, 1]\n",
    "    original_image = np.uint8(original_image * 255)  # Scale to 0-255\n",
    "    \n",
    "    # Blend original image and saliency map\n",
    "    alpha = 0.5\n",
    "    blended = np.uint8(original_image * (1 - alpha) + saliency_colormap * alpha)\n",
    "    \n",
    "    # Plot original, saliency map, and overlay\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('Original Image')\n",
    "    plt.imshow(original_image.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('Saliency Map')\n",
    "    plt.imshow(saliency_map[0], cmap='hot')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('Overlay with Saliency')\n",
    "    plt.imshow(blended)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot saliency maps for the best and worst predictions\n",
    "if worst_idx is not None:\n",
    "    print(f\"Plotting saliency map for worst prediction (Index: {worst_idx}, True Label: {class_mapping[worst_label]}, Predicted: {class_mapping[worst_pred_class]}, Filename: {worst_filename})\")\n",
    "    plot_saliency_map(worst_image, model_ready, np.argmax(predictions[worst_idx]))\n",
    "\n",
    "print(f\"Plotting saliency map for best prediction (Index: {best_idx}, True Label: {class_mapping[best_label]}, Predicted: {class_mapping[best_pred_class]}, Filename: {best_filename})\")\n",
    "plot_saliency_map(best_image, model_ready, np.argmax(predictions[best_idx]))\n",
    "\n",
    "# Processing time\n",
    "print(f\"Processing time: {time.time() - start_time} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
